{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech tagging using CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sklearn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "wsj = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n",
      "3914\n"
     ]
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "print(wsj[:2])\n",
    "print(len(wsj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Brown tagged sentences\n",
    "brown= list(nltk.corpus.brown.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')]]\n",
      "57340\n"
     ]
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "print(brown[:2])\n",
    "print(len(brown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the conll2000 tagged sentences\n",
    "conll2000= list(nltk.corpus.conll2000.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Confidence', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('pound', 'NOUN'), ('is', 'VERB'), ('widely', 'ADV'), ('expected', 'VERB'), ('to', 'PRT'), ('take', 'VERB'), ('another', 'DET'), ('sharp', 'ADJ'), ('dive', 'NOUN'), ('if', 'ADP'), ('trade', 'NOUN'), ('figures', 'NOUN'), ('for', 'ADP'), ('September', 'NOUN'), (',', '.'), ('due', 'ADJ'), ('for', 'ADP'), ('release', 'NOUN'), ('tomorrow', 'NOUN'), (',', '.'), ('fail', 'VERB'), ('to', 'PRT'), ('show', 'VERB'), ('a', 'DET'), ('substantial', 'ADJ'), ('improvement', 'NOUN'), ('from', 'ADP'), ('July', 'NOUN'), ('and', 'CONJ'), ('August', 'NOUN'), (\"'s\", 'PRT'), ('near-record', 'ADJ'), ('deficits', 'NOUN'), ('.', '.')], [('Chancellor', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Exchequer', 'NOUN'), ('Nigel', 'NOUN'), ('Lawson', 'NOUN'), (\"'s\", 'PRT'), ('restated', 'VERB'), ('commitment', 'NOUN'), ('to', 'PRT'), ('a', 'DET'), ('firm', 'NOUN'), ('monetary', 'ADJ'), ('policy', 'NOUN'), ('has', 'VERB'), ('helped', 'VERB'), ('to', 'PRT'), ('prevent', 'VERB'), ('a', 'DET'), ('freefall', 'NOUN'), ('in', 'ADP'), ('sterling', 'NOUN'), ('over', 'ADP'), ('the', 'DET'), ('past', 'ADJ'), ('week', 'NOUN'), ('.', '.')]]\n",
      "10948\n"
     ]
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "print(conll2000[:2])\n",
    "print(len(conll2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_data = wsj + brown + conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n",
      "72202\n"
     ]
    }
   ],
   "source": [
    "print(nltk_data[:2])\n",
    "print(len(nltk_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('chairman', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Elsevier', 'NOUN'),\n",
       " ('N.V.', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('Dutch', 'NOUN'),\n",
       " ('publishing', 'VERB'),\n",
       " ('group', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build your CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from a given sentence\n",
    "\n",
    "def word_features(sent, i):\n",
    "    word = sent[i][0]    \n",
    "    features = {\n",
    "            'word':word,\n",
    "            'bias': 1.0,\n",
    "            'is_capitalized': word[0].upper() == word[0],\n",
    "            'is_all_caps': word.upper() == word,\n",
    "            'is_all_lower': word.lower() == word,\n",
    "            'is_numeric': word.isdigit(),\n",
    "            'has_no_digit': None==re.search(r'[0-9]+',word),\n",
    "            'has_no_punc': None==re.search(r'[\\.\\,\\:\\;\\(\\)\\[\\]\\?\\!]+',word),\n",
    "            'has_no_only_punc': None==re.search(r'^[\\.\\,\\:\\;\\(\\)\\[\\]\\?\\!]+$',word),\n",
    "            'capitals_inside': word[1:].lower() != word[1:],\n",
    "            'has_no_ing': None==re.search(r'.*ing$', word),             \n",
    "            'has_no_ed': None==re.search(r'.*ed$', word),              \n",
    "            'has_no_es': None==re.search(r'.*es$', word),               \n",
    "            'has_no_ould': None==re.search(r'.*ould$', word),              \n",
    "            'is_no_possessive':None==re.search(r'.*\\'s$', word),              \n",
    "            'is_no_plural': None==re.search(r'.*s$', word), \n",
    "            'is_no_cardinal': None==re.search(r'^-?[0-9]+(.[0-9]+)?$', word),\n",
    "            'suff_1': word[-1:],  \n",
    "            'suff_2': word[-2:],  \n",
    "            'suff_3': word[-3:],  \n",
    "            'suff_4': word[-4:], \n",
    "            'pref_1': word[:1],  \n",
    "            'pref_2': word[:2],  \n",
    "            'pref_3': word[:3], \n",
    "            'pref_4': word[:4],\n",
    "            'lemma': stemmer.stem(word),\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "\n",
    "        features.update({   \n",
    "            '-1:word' : word1,\n",
    "            '-1:is_capitalized': word1.upper() == word1,\n",
    "            '-1:is_all_caps': word1.upper() == word1,\n",
    "            '-1:is_all_lower': word1.lower() == word1,\n",
    "            '-1:has_no_digit': None==re.search(r'[0-9]+',word1),\n",
    "            '-1:has_no_punc': None==re.search(r'[\\.\\,\\:\\;\\(\\)\\[\\]\\?\\!]+',word1),\n",
    "            '-1:has_no_only_punc': None==re.search(r'^[\\.\\,\\:\\;\\(\\)\\[\\]\\?\\!]+$',word1),\n",
    "            '-1:capitals_inside': word[1:].lower() != word1[1:],\n",
    "            '-1:has_no_ing': None==re.search(r'.*ing$', word1),             \n",
    "            '-1:has_no_ed': None==re.search(r'.*ed$', word1),              \n",
    "            '-1:has_no_es': None==re.search(r'.*es$', word1),               \n",
    "            '-1:has_no_ould': None==re.search(r'.*ould$', word1),              \n",
    "            '-1:is_no_possessive':None==re.search(r'.*\\'s$', word1),              \n",
    "            '-1:is_no_plural': None==re.search(r'.*s$', word1), \n",
    "            '-1:is_no_cardinal': None==re.search(r'^-?[0-9]+(.[0-9]+)?$', word1),\n",
    "            '-1:suff_1': word1[-1:],  \n",
    "            '-1:suff_2': word1[-2:],  \n",
    "            '-1:suff_3': word1[-3:],  \n",
    "            '-1:suff_4': word1[-4:], \n",
    "            '-1:pref_1': word1[:1],  \n",
    "            '-1:pref_2': word1[:2],  \n",
    "            '-1:pref_3': word1[:3], \n",
    "            '-1:pref_4': word1[:4],\n",
    "            '-1:lemma': stemmer.stem(word1),\n",
    "        })\n",
    "    else:\n",
    "        features.update({   \n",
    "            '-1:word': '<START>',\n",
    "        })\n",
    "    \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word': word1,\n",
    "            '+1:is_capitalized': word1.upper() == word1,\n",
    "            '+1:is_all_caps': word1.upper() == word1,\n",
    "            '+1:is_all_lower': word1.lower() == word1,\n",
    "            '+1:is_numeric': word1.isdigit(),\n",
    "            '+1:has_no_digit': None==re.search(r'[0-9]+',word1),\n",
    "            '+1:has_no_punc': None==re.search(r'[\\.\\,\\:\\;\\(\\)\\[\\]\\?\\!]+',word1),\n",
    "            '+1:has_no_only_punc': None==re.search(r'^[\\.\\,\\:\\;\\(\\)\\[\\]\\?\\!]+$',word1),\n",
    "            '+1:capitals_inside': word[1:].lower() != word1[1:],\n",
    "            '+1:has_no_ing': None==re.search(r'.*ing$', word1),             \n",
    "            '+1:has_no_ed': None==re.search(r'.*ed$', word1),              \n",
    "            '+1:has_no_es': None==re.search(r'.*es$', word1),               \n",
    "            '+1:has_no_ould': None==re.search(r'.*ould$', word1),              \n",
    "            '+1:is_no_possessive':None==re.search(r'.*\\'s$', word1),              \n",
    "            '+1:is_no_plural': None==re.search(r'.*s$', word1), \n",
    "            '+1:is_no_cardinal': None==re.search(r'^-?[0-9]+(.[0-9]+)?$', word1),\n",
    "            '+1:suff_1': word1[-1:],  \n",
    "            '+1:suff_2': word1[-2:],  \n",
    "            '+1:suff_3': word1[-3:],  \n",
    "            '+1:suff_4': word1[-4:], \n",
    "            '+1:pref_1': word1[:1],  \n",
    "            '+1:pref_2': word1[:2],  \n",
    "            '+1:pref_3': word1[:3], \n",
    "            '+1:pref_4': word1[:4],\n",
    "            '+1:lemma': stemmer.stem(word1),\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            '+1:word': '<END>',\n",
    "        })\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word_features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2pos(sent):\n",
    "    return [postag for token, postag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(sent) for sent in nltk_data]\n",
    "y = [sent2pos(sent) for sent in nltk_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': False,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'vinken',\n",
       "  '+1:pref_1': 'V',\n",
       "  '+1:pref_2': 'Vi',\n",
       "  '+1:pref_3': 'Vin',\n",
       "  '+1:pref_4': 'Vink',\n",
       "  '+1:suff_1': 'n',\n",
       "  '+1:suff_2': 'en',\n",
       "  '+1:suff_3': 'ken',\n",
       "  '+1:suff_4': 'nken',\n",
       "  '+1:word': 'Vinken',\n",
       "  '-1:word': '<START>',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'pierr',\n",
       "  'pref_1': 'P',\n",
       "  'pref_2': 'Pi',\n",
       "  'pref_3': 'Pie',\n",
       "  'pref_4': 'Pier',\n",
       "  'suff_1': 'e',\n",
       "  'suff_2': 're',\n",
       "  'suff_3': 'rre',\n",
       "  'suff_4': 'erre',\n",
       "  'word': 'Pierre'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': False,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': False,\n",
       "  '+1:is_all_caps': True,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': True,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': ',',\n",
       "  '+1:pref_1': ',',\n",
       "  '+1:pref_2': ',',\n",
       "  '+1:pref_3': ',',\n",
       "  '+1:pref_4': ',',\n",
       "  '+1:suff_1': ',',\n",
       "  '+1:suff_2': ',',\n",
       "  '+1:suff_3': ',',\n",
       "  '+1:suff_4': ',',\n",
       "  '+1:word': ',',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': False,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'pierr',\n",
       "  '-1:pref_1': 'P',\n",
       "  '-1:pref_2': 'Pi',\n",
       "  '-1:pref_3': 'Pie',\n",
       "  '-1:pref_4': 'Pier',\n",
       "  '-1:suff_1': 'e',\n",
       "  '-1:suff_2': 're',\n",
       "  '-1:suff_3': 'rre',\n",
       "  '-1:suff_4': 'erre',\n",
       "  '-1:word': 'Pierre',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'vinken',\n",
       "  'pref_1': 'V',\n",
       "  'pref_2': 'Vi',\n",
       "  'pref_3': 'Vin',\n",
       "  'pref_4': 'Vink',\n",
       "  'suff_1': 'n',\n",
       "  'suff_2': 'en',\n",
       "  'suff_3': 'ken',\n",
       "  'suff_4': 'nken',\n",
       "  'word': 'Vinken'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': False,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': True,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': True,\n",
       "  '+1:is_no_cardinal': False,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': True,\n",
       "  '+1:lemma': '61',\n",
       "  '+1:pref_1': '6',\n",
       "  '+1:pref_2': '61',\n",
       "  '+1:pref_3': '61',\n",
       "  '+1:pref_4': '61',\n",
       "  '+1:suff_1': '1',\n",
       "  '+1:suff_2': '61',\n",
       "  '+1:suff_3': '61',\n",
       "  '+1:suff_4': '61',\n",
       "  '+1:word': '61',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': False,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'vinken',\n",
       "  '-1:pref_1': 'V',\n",
       "  '-1:pref_2': 'Vi',\n",
       "  '-1:pref_3': 'Vin',\n",
       "  '-1:pref_4': 'Vink',\n",
       "  '-1:suff_1': 'n',\n",
       "  '-1:suff_2': 'en',\n",
       "  '-1:suff_3': 'ken',\n",
       "  '-1:suff_4': 'nken',\n",
       "  '-1:word': 'Vinken',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': False,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': False,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': ',',\n",
       "  'pref_1': ',',\n",
       "  'pref_2': ',',\n",
       "  'pref_3': ',',\n",
       "  'pref_4': ',',\n",
       "  'suff_1': ',',\n",
       "  'suff_2': ',',\n",
       "  'suff_3': ',',\n",
       "  'suff_4': ',',\n",
       "  'word': ','},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': False,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'year',\n",
       "  '+1:pref_1': 'y',\n",
       "  '+1:pref_2': 'ye',\n",
       "  '+1:pref_3': 'yea',\n",
       "  '+1:pref_4': 'year',\n",
       "  '+1:suff_1': 's',\n",
       "  '+1:suff_2': 'rs',\n",
       "  '+1:suff_3': 'ars',\n",
       "  '+1:suff_4': 'ears',\n",
       "  '+1:word': 'years',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': False,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': False,\n",
       "  '-1:is_all_caps': True,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': True,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': ',',\n",
       "  '-1:pref_1': ',',\n",
       "  '-1:pref_2': ',',\n",
       "  '-1:pref_3': ',',\n",
       "  '-1:pref_4': ',',\n",
       "  '-1:suff_1': ',',\n",
       "  '-1:suff_2': ',',\n",
       "  '-1:suff_3': ',',\n",
       "  '-1:suff_4': ',',\n",
       "  '-1:word': ',',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': False,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': False,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': True,\n",
       "  'lemma': '61',\n",
       "  'pref_1': '6',\n",
       "  'pref_2': '61',\n",
       "  'pref_3': '61',\n",
       "  'pref_4': '61',\n",
       "  'suff_1': '1',\n",
       "  'suff_2': '61',\n",
       "  'suff_3': '61',\n",
       "  'suff_4': '61',\n",
       "  'word': '61'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'old',\n",
       "  '+1:pref_1': 'o',\n",
       "  '+1:pref_2': 'ol',\n",
       "  '+1:pref_3': 'old',\n",
       "  '+1:pref_4': 'old',\n",
       "  '+1:suff_1': 'd',\n",
       "  '+1:suff_2': 'ld',\n",
       "  '+1:suff_3': 'old',\n",
       "  '+1:suff_4': 'old',\n",
       "  '+1:word': 'old',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': False,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': True,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': True,\n",
       "  '-1:is_no_cardinal': False,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': '61',\n",
       "  '-1:pref_1': '6',\n",
       "  '-1:pref_2': '61',\n",
       "  '-1:pref_3': '61',\n",
       "  '-1:pref_4': '61',\n",
       "  '-1:suff_1': '1',\n",
       "  '-1:suff_2': '61',\n",
       "  '-1:suff_3': '61',\n",
       "  '-1:suff_4': '61',\n",
       "  '-1:word': '61',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': False,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'year',\n",
       "  'pref_1': 'y',\n",
       "  'pref_2': 'ye',\n",
       "  'pref_3': 'yea',\n",
       "  'pref_4': 'year',\n",
       "  'suff_1': 's',\n",
       "  'suff_2': 'rs',\n",
       "  'suff_3': 'ars',\n",
       "  'suff_4': 'ears',\n",
       "  'word': 'years'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': False,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': False,\n",
       "  '+1:is_all_caps': True,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': True,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': ',',\n",
       "  '+1:pref_1': ',',\n",
       "  '+1:pref_2': ',',\n",
       "  '+1:pref_3': ',',\n",
       "  '+1:pref_4': ',',\n",
       "  '+1:suff_1': ',',\n",
       "  '+1:suff_2': ',',\n",
       "  '+1:suff_3': ',',\n",
       "  '+1:suff_4': ',',\n",
       "  '+1:word': ',',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': False,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'year',\n",
       "  '-1:pref_1': 'y',\n",
       "  '-1:pref_2': 'ye',\n",
       "  '-1:pref_3': 'yea',\n",
       "  '-1:pref_4': 'year',\n",
       "  '-1:suff_1': 's',\n",
       "  '-1:suff_2': 'rs',\n",
       "  '-1:suff_3': 'ars',\n",
       "  '-1:suff_4': 'ears',\n",
       "  '-1:word': 'years',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'old',\n",
       "  'pref_1': 'o',\n",
       "  'pref_2': 'ol',\n",
       "  'pref_3': 'old',\n",
       "  'pref_4': 'old',\n",
       "  'suff_1': 'd',\n",
       "  'suff_2': 'ld',\n",
       "  'suff_3': 'old',\n",
       "  'suff_4': 'old',\n",
       "  'word': 'old'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'will',\n",
       "  '+1:pref_1': 'w',\n",
       "  '+1:pref_2': 'wi',\n",
       "  '+1:pref_3': 'wil',\n",
       "  '+1:pref_4': 'will',\n",
       "  '+1:suff_1': 'l',\n",
       "  '+1:suff_2': 'll',\n",
       "  '+1:suff_3': 'ill',\n",
       "  '+1:suff_4': 'will',\n",
       "  '+1:word': 'will',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'old',\n",
       "  '-1:pref_1': 'o',\n",
       "  '-1:pref_2': 'ol',\n",
       "  '-1:pref_3': 'old',\n",
       "  '-1:pref_4': 'old',\n",
       "  '-1:suff_1': 'd',\n",
       "  '-1:suff_2': 'ld',\n",
       "  '-1:suff_3': 'old',\n",
       "  '-1:suff_4': 'old',\n",
       "  '-1:word': 'old',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': False,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': False,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': ',',\n",
       "  'pref_1': ',',\n",
       "  'pref_2': ',',\n",
       "  'pref_3': ',',\n",
       "  'pref_4': ',',\n",
       "  'suff_1': ',',\n",
       "  'suff_2': ',',\n",
       "  'suff_3': ',',\n",
       "  'suff_4': ',',\n",
       "  'word': ','},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'join',\n",
       "  '+1:pref_1': 'j',\n",
       "  '+1:pref_2': 'jo',\n",
       "  '+1:pref_3': 'joi',\n",
       "  '+1:pref_4': 'join',\n",
       "  '+1:suff_1': 'n',\n",
       "  '+1:suff_2': 'in',\n",
       "  '+1:suff_3': 'oin',\n",
       "  '+1:suff_4': 'join',\n",
       "  '+1:word': 'join',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': False,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': False,\n",
       "  '-1:is_all_caps': True,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': True,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': ',',\n",
       "  '-1:pref_1': ',',\n",
       "  '-1:pref_2': ',',\n",
       "  '-1:pref_3': ',',\n",
       "  '-1:pref_4': ',',\n",
       "  '-1:suff_1': ',',\n",
       "  '-1:suff_2': ',',\n",
       "  '-1:suff_3': ',',\n",
       "  '-1:suff_4': ',',\n",
       "  '-1:word': ',',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'will',\n",
       "  'pref_1': 'w',\n",
       "  'pref_2': 'wi',\n",
       "  'pref_3': 'wil',\n",
       "  'pref_4': 'will',\n",
       "  'suff_1': 'l',\n",
       "  'suff_2': 'll',\n",
       "  'suff_3': 'ill',\n",
       "  'suff_4': 'will',\n",
       "  'word': 'will'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'the',\n",
       "  '+1:pref_1': 't',\n",
       "  '+1:pref_2': 'th',\n",
       "  '+1:pref_3': 'the',\n",
       "  '+1:pref_4': 'the',\n",
       "  '+1:suff_1': 'e',\n",
       "  '+1:suff_2': 'he',\n",
       "  '+1:suff_3': 'the',\n",
       "  '+1:suff_4': 'the',\n",
       "  '+1:word': 'the',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'will',\n",
       "  '-1:pref_1': 'w',\n",
       "  '-1:pref_2': 'wi',\n",
       "  '-1:pref_3': 'wil',\n",
       "  '-1:pref_4': 'will',\n",
       "  '-1:suff_1': 'l',\n",
       "  '-1:suff_2': 'll',\n",
       "  '-1:suff_3': 'ill',\n",
       "  '-1:suff_4': 'will',\n",
       "  '-1:word': 'will',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'join',\n",
       "  'pref_1': 'j',\n",
       "  'pref_2': 'jo',\n",
       "  'pref_3': 'joi',\n",
       "  'pref_4': 'join',\n",
       "  'suff_1': 'n',\n",
       "  'suff_2': 'in',\n",
       "  'suff_3': 'oin',\n",
       "  'suff_4': 'join',\n",
       "  'word': 'join'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'board',\n",
       "  '+1:pref_1': 'b',\n",
       "  '+1:pref_2': 'bo',\n",
       "  '+1:pref_3': 'boa',\n",
       "  '+1:pref_4': 'boar',\n",
       "  '+1:suff_1': 'd',\n",
       "  '+1:suff_2': 'rd',\n",
       "  '+1:suff_3': 'ard',\n",
       "  '+1:suff_4': 'oard',\n",
       "  '+1:word': 'board',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'join',\n",
       "  '-1:pref_1': 'j',\n",
       "  '-1:pref_2': 'jo',\n",
       "  '-1:pref_3': 'joi',\n",
       "  '-1:pref_4': 'join',\n",
       "  '-1:suff_1': 'n',\n",
       "  '-1:suff_2': 'in',\n",
       "  '-1:suff_3': 'oin',\n",
       "  '-1:suff_4': 'join',\n",
       "  '-1:word': 'join',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'the',\n",
       "  'pref_1': 't',\n",
       "  'pref_2': 'th',\n",
       "  'pref_3': 'the',\n",
       "  'pref_4': 'the',\n",
       "  'suff_1': 'e',\n",
       "  'suff_2': 'he',\n",
       "  'suff_3': 'the',\n",
       "  'suff_4': 'the',\n",
       "  'word': 'the'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': False,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'as',\n",
       "  '+1:pref_1': 'a',\n",
       "  '+1:pref_2': 'as',\n",
       "  '+1:pref_3': 'as',\n",
       "  '+1:pref_4': 'as',\n",
       "  '+1:suff_1': 's',\n",
       "  '+1:suff_2': 'as',\n",
       "  '+1:suff_3': 'as',\n",
       "  '+1:suff_4': 'as',\n",
       "  '+1:word': 'as',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'the',\n",
       "  '-1:pref_1': 't',\n",
       "  '-1:pref_2': 'th',\n",
       "  '-1:pref_3': 'the',\n",
       "  '-1:pref_4': 'the',\n",
       "  '-1:suff_1': 'e',\n",
       "  '-1:suff_2': 'he',\n",
       "  '-1:suff_3': 'the',\n",
       "  '-1:suff_4': 'the',\n",
       "  '-1:word': 'the',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'board',\n",
       "  'pref_1': 'b',\n",
       "  'pref_2': 'bo',\n",
       "  'pref_3': 'boa',\n",
       "  'pref_4': 'boar',\n",
       "  'suff_1': 'd',\n",
       "  'suff_2': 'rd',\n",
       "  'suff_3': 'ard',\n",
       "  'suff_4': 'oard',\n",
       "  'word': 'board'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'a',\n",
       "  '+1:pref_1': 'a',\n",
       "  '+1:pref_2': 'a',\n",
       "  '+1:pref_3': 'a',\n",
       "  '+1:pref_4': 'a',\n",
       "  '+1:suff_1': 'a',\n",
       "  '+1:suff_2': 'a',\n",
       "  '+1:suff_3': 'a',\n",
       "  '+1:suff_4': 'a',\n",
       "  '+1:word': 'a',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'board',\n",
       "  '-1:pref_1': 'b',\n",
       "  '-1:pref_2': 'bo',\n",
       "  '-1:pref_3': 'boa',\n",
       "  '-1:pref_4': 'boar',\n",
       "  '-1:suff_1': 'd',\n",
       "  '-1:suff_2': 'rd',\n",
       "  '-1:suff_3': 'ard',\n",
       "  '-1:suff_4': 'oard',\n",
       "  '-1:word': 'board',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': False,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'as',\n",
       "  'pref_1': 'a',\n",
       "  'pref_2': 'as',\n",
       "  'pref_3': 'as',\n",
       "  'pref_4': 'as',\n",
       "  'suff_1': 's',\n",
       "  'suff_2': 'as',\n",
       "  'suff_3': 'as',\n",
       "  'suff_4': 'as',\n",
       "  'word': 'as'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'nonexecut',\n",
       "  '+1:pref_1': 'n',\n",
       "  '+1:pref_2': 'no',\n",
       "  '+1:pref_3': 'non',\n",
       "  '+1:pref_4': 'none',\n",
       "  '+1:suff_1': 'e',\n",
       "  '+1:suff_2': 've',\n",
       "  '+1:suff_3': 'ive',\n",
       "  '+1:suff_4': 'tive',\n",
       "  '+1:word': 'nonexecutive',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': False,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'as',\n",
       "  '-1:pref_1': 'a',\n",
       "  '-1:pref_2': 'as',\n",
       "  '-1:pref_3': 'as',\n",
       "  '-1:pref_4': 'as',\n",
       "  '-1:suff_1': 's',\n",
       "  '-1:suff_2': 'as',\n",
       "  '-1:suff_3': 'as',\n",
       "  '-1:suff_4': 'as',\n",
       "  '-1:word': 'as',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'a',\n",
       "  'pref_1': 'a',\n",
       "  'pref_2': 'a',\n",
       "  'pref_3': 'a',\n",
       "  'pref_4': 'a',\n",
       "  'suff_1': 'a',\n",
       "  'suff_2': 'a',\n",
       "  'suff_3': 'a',\n",
       "  'suff_4': 'a',\n",
       "  'word': 'a'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'director',\n",
       "  '+1:pref_1': 'd',\n",
       "  '+1:pref_2': 'di',\n",
       "  '+1:pref_3': 'dir',\n",
       "  '+1:pref_4': 'dire',\n",
       "  '+1:suff_1': 'r',\n",
       "  '+1:suff_2': 'or',\n",
       "  '+1:suff_3': 'tor',\n",
       "  '+1:suff_4': 'ctor',\n",
       "  '+1:word': 'director',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'a',\n",
       "  '-1:pref_1': 'a',\n",
       "  '-1:pref_2': 'a',\n",
       "  '-1:pref_3': 'a',\n",
       "  '-1:pref_4': 'a',\n",
       "  '-1:suff_1': 'a',\n",
       "  '-1:suff_2': 'a',\n",
       "  '-1:suff_3': 'a',\n",
       "  '-1:suff_4': 'a',\n",
       "  '-1:word': 'a',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'nonexecut',\n",
       "  'pref_1': 'n',\n",
       "  'pref_2': 'no',\n",
       "  'pref_3': 'non',\n",
       "  'pref_4': 'none',\n",
       "  'suff_1': 'e',\n",
       "  'suff_2': 've',\n",
       "  'suff_3': 'ive',\n",
       "  'suff_4': 'tive',\n",
       "  'word': 'nonexecutive'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': False,\n",
       "  '+1:is_all_caps': False,\n",
       "  '+1:is_all_lower': False,\n",
       "  '+1:is_capitalized': False,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': 'nov.',\n",
       "  '+1:pref_1': 'N',\n",
       "  '+1:pref_2': 'No',\n",
       "  '+1:pref_3': 'Nov',\n",
       "  '+1:pref_4': 'Nov.',\n",
       "  '+1:suff_1': '.',\n",
       "  '+1:suff_2': 'v.',\n",
       "  '+1:suff_3': 'ov.',\n",
       "  '+1:suff_4': 'Nov.',\n",
       "  '+1:word': 'Nov.',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'nonexecut',\n",
       "  '-1:pref_1': 'n',\n",
       "  '-1:pref_2': 'no',\n",
       "  '-1:pref_3': 'non',\n",
       "  '-1:pref_4': 'none',\n",
       "  '-1:suff_1': 'e',\n",
       "  '-1:suff_2': 've',\n",
       "  '-1:suff_3': 'ive',\n",
       "  '-1:suff_4': 'tive',\n",
       "  '-1:word': 'nonexecutive',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': False,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'director',\n",
       "  'pref_1': 'd',\n",
       "  'pref_2': 'di',\n",
       "  'pref_3': 'dir',\n",
       "  'pref_4': 'dire',\n",
       "  'suff_1': 'r',\n",
       "  'suff_2': 'or',\n",
       "  'suff_3': 'tor',\n",
       "  'suff_4': 'ctor',\n",
       "  'word': 'director'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': False,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': True,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': True,\n",
       "  '+1:is_all_caps': True,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': True,\n",
       "  '+1:is_no_cardinal': False,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': True,\n",
       "  '+1:lemma': '29',\n",
       "  '+1:pref_1': '2',\n",
       "  '+1:pref_2': '29',\n",
       "  '+1:pref_3': '29',\n",
       "  '+1:pref_4': '29',\n",
       "  '+1:suff_1': '9',\n",
       "  '+1:suff_2': '29',\n",
       "  '+1:suff_3': '29',\n",
       "  '+1:suff_4': '29',\n",
       "  '+1:word': '29',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'director',\n",
       "  '-1:pref_1': 'd',\n",
       "  '-1:pref_2': 'di',\n",
       "  '-1:pref_3': 'dir',\n",
       "  '-1:pref_4': 'dire',\n",
       "  '-1:suff_1': 'r',\n",
       "  '-1:suff_2': 'or',\n",
       "  '-1:suff_3': 'tor',\n",
       "  '-1:suff_4': 'ctor',\n",
       "  '-1:word': 'director',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': False,\n",
       "  'is_all_caps': False,\n",
       "  'is_all_lower': False,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': 'nov.',\n",
       "  'pref_1': 'N',\n",
       "  'pref_2': 'No',\n",
       "  'pref_3': 'Nov',\n",
       "  'pref_4': 'Nov.',\n",
       "  'suff_1': '.',\n",
       "  'suff_2': 'v.',\n",
       "  'suff_3': 'ov.',\n",
       "  'suff_4': 'Nov.',\n",
       "  'word': 'Nov.'},\n",
       " {'+1:capitals_inside': True,\n",
       "  '+1:has_no_digit': True,\n",
       "  '+1:has_no_ed': True,\n",
       "  '+1:has_no_es': True,\n",
       "  '+1:has_no_ing': True,\n",
       "  '+1:has_no_only_punc': False,\n",
       "  '+1:has_no_ould': True,\n",
       "  '+1:has_no_punc': False,\n",
       "  '+1:is_all_caps': True,\n",
       "  '+1:is_all_lower': True,\n",
       "  '+1:is_capitalized': True,\n",
       "  '+1:is_no_cardinal': True,\n",
       "  '+1:is_no_plural': True,\n",
       "  '+1:is_no_possessive': True,\n",
       "  '+1:is_numeric': False,\n",
       "  '+1:lemma': '.',\n",
       "  '+1:pref_1': '.',\n",
       "  '+1:pref_2': '.',\n",
       "  '+1:pref_3': '.',\n",
       "  '+1:pref_4': '.',\n",
       "  '+1:suff_1': '.',\n",
       "  '+1:suff_2': '.',\n",
       "  '+1:suff_3': '.',\n",
       "  '+1:suff_4': '.',\n",
       "  '+1:word': '.',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': True,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': False,\n",
       "  '-1:is_all_caps': False,\n",
       "  '-1:is_all_lower': False,\n",
       "  '-1:is_capitalized': False,\n",
       "  '-1:is_no_cardinal': True,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': 'nov.',\n",
       "  '-1:pref_1': 'N',\n",
       "  '-1:pref_2': 'No',\n",
       "  '-1:pref_3': 'Nov',\n",
       "  '-1:pref_4': 'Nov.',\n",
       "  '-1:suff_1': '.',\n",
       "  '-1:suff_2': 'v.',\n",
       "  '-1:suff_3': 'ov.',\n",
       "  '-1:suff_4': 'Nov.',\n",
       "  '-1:word': 'Nov.',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': False,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': True,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': True,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': False,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': True,\n",
       "  'lemma': '29',\n",
       "  'pref_1': '2',\n",
       "  'pref_2': '29',\n",
       "  'pref_3': '29',\n",
       "  'pref_4': '29',\n",
       "  'suff_1': '9',\n",
       "  'suff_2': '29',\n",
       "  'suff_3': '29',\n",
       "  'suff_4': '29',\n",
       "  'word': '29'},\n",
       " {'+1:word': '<END>',\n",
       "  '-1:capitals_inside': True,\n",
       "  '-1:has_no_digit': False,\n",
       "  '-1:has_no_ed': True,\n",
       "  '-1:has_no_es': True,\n",
       "  '-1:has_no_ing': True,\n",
       "  '-1:has_no_only_punc': True,\n",
       "  '-1:has_no_ould': True,\n",
       "  '-1:has_no_punc': True,\n",
       "  '-1:is_all_caps': True,\n",
       "  '-1:is_all_lower': True,\n",
       "  '-1:is_capitalized': True,\n",
       "  '-1:is_no_cardinal': False,\n",
       "  '-1:is_no_plural': True,\n",
       "  '-1:is_no_possessive': True,\n",
       "  '-1:lemma': '29',\n",
       "  '-1:pref_1': '2',\n",
       "  '-1:pref_2': '29',\n",
       "  '-1:pref_3': '29',\n",
       "  '-1:pref_4': '29',\n",
       "  '-1:suff_1': '9',\n",
       "  '-1:suff_2': '29',\n",
       "  '-1:suff_3': '29',\n",
       "  '-1:suff_4': '29',\n",
       "  '-1:word': '29',\n",
       "  'bias': 1.0,\n",
       "  'capitals_inside': False,\n",
       "  'has_no_digit': True,\n",
       "  'has_no_ed': True,\n",
       "  'has_no_es': True,\n",
       "  'has_no_ing': True,\n",
       "  'has_no_only_punc': False,\n",
       "  'has_no_ould': True,\n",
       "  'has_no_punc': False,\n",
       "  'is_all_caps': True,\n",
       "  'is_all_lower': True,\n",
       "  'is_capitalized': True,\n",
       "  'is_no_cardinal': True,\n",
       "  'is_no_plural': True,\n",
       "  'is_no_possessive': True,\n",
       "  'is_numeric': False,\n",
       "  'lemma': '.',\n",
       "  'pref_1': '.',\n",
       "  'pref_2': '.',\n",
       "  'pref_3': '.',\n",
       "  'pref_4': '.',\n",
       "  'suff_1': '.',\n",
       "  'suff_2': '.',\n",
       "  'suff_3': '.',\n",
       "  'suff_4': '.',\n",
       "  'word': '.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# pip/conda install sklearn_crfsuite\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9509576492962789"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      0.999     0.999     0.999     38387\n",
      "          X      0.981     0.833     0.901      1589\n",
      "        ADJ      0.860     0.844     0.852     21451\n",
      "        ADP      0.959     0.967     0.963     36649\n",
      "        ADV      0.910     0.891     0.900     13706\n",
      "       VERB      0.952     0.950     0.951     46647\n",
      "        DET      0.974     0.983     0.978     34071\n",
      "       CONJ      0.992     0.992     0.992      9518\n",
      "       NOUN      0.942     0.956     0.949     77256\n",
      "       PRON      0.981     0.921     0.950     11865\n",
      "        PRT      0.880     0.874     0.877      8289\n",
      "        NUM      0.975     0.962     0.969      5776\n",
      "\n",
      "avg / total      0.951     0.951     0.951    305204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\python3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import scipy\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=3,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Interpret the model (enlist important state and transition features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
